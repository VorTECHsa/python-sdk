{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83e3e69c",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2418cf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T10:23:07.829143Z",
     "start_time": "2024-09-17T10:23:01.484040Z"
    }
   },
   "outputs": [],
   "source": [
    "import vortexasdk as v\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import time\n",
    "import dateutil.relativedelta\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from statsmodels.tsa.stattools import grangercausalitytests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d842ed2",
   "metadata": {},
   "source": [
    "# Search Geography & Product IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5a06b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T10:23:07.851421Z",
     "start_time": "2024-09-17T10:23:07.846064Z"
    }
   },
   "outputs": [],
   "source": [
    "# search for geography ids (remove hashtags to search)\n",
    "\n",
    "# full_length_df = v.Geographies().search(term=[\"US Gulf Coast\"]).to_df()\n",
    "# print(full_length_df.to_string(index=False))\n",
    "\n",
    "meg='0427e0f9d52b38c1a98b68c59b8fd80cb1c508e44882e96611e48ef5b140d927'\n",
    "padd3='4e79eb8e84d26f5c3c0006283bc1aa52c170b58d667be9848e136afea91a57e9'\n",
    "nwe='c5460c5a4ece7b64ffc0cc280aeade60d364423e8e062ef4a11494352fe6fdbb'\n",
    "gom='37c8c4eeb730d1cd41f90ca6bf95c923222b0734b1b0336a475acce821f87ebd'\n",
    "\n",
    "# search for product ids (remove hashtags below to search)\n",
    "\n",
    "# product_search = v.Products().search(term=['naphtha']).to_df()\n",
    "# print (product_search.to_string(index=False))\n",
    "\n",
    "cpp='b68cbb746f8b9098c50e2ba36bcad83001a53bd362e9031fb49085d02c36659c'\n",
    "lpg='364ccbb996c944055b479810a8e74863267885dc1b01407cb0f00ab26dafe1e1'\n",
    "naphtha='3e4db72ef7027de928ce55703a213a546fd86d2debe6f2e9c85f3a5f9d53e8dd'\n",
    "diesel_go='deda35eb9ca56b54e74f0ff370423f9a8c61cf6a3796fcb18eaeeb32a8c290bb'\n",
    "crude_co='54af755a090118dcf9b0724c9a4e9f14745c26165385ffa7f1445bc768f06f11'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f18c8c",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623d3bd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T10:23:07.908270Z",
     "start_time": "2024-09-17T10:23:07.857094Z"
    }
   },
   "outputs": [],
   "source": [
    "# function to create a moving average\n",
    "def moving_average(data, period, option):\n",
    "    \n",
    "    if option=='multiple':\n",
    "\n",
    "        # calculate moving avg\n",
    "        moving_avg = pd.DataFrame(data.iloc[:, 1:].rolling(window=period, min_periods=1).mean())\n",
    "\n",
    "        # add moving average\n",
    "        moving_avg_df=pd.concat([data.iloc[0:, 0:1], moving_avg], axis=1)\n",
    "\n",
    "        moving_avg_df.columns=list(data.columns)\n",
    "        \n",
    "    elif option=='single':\n",
    "        \n",
    "        # calculate moving avg\n",
    "        moving_avg = pd.DataFrame(data['value'].rolling(window=period, min_periods=1).mean())\n",
    "        moving_avg.columns=[f'{period}-day moving_avg']\n",
    "\n",
    "        # get all columns\n",
    "        data_cols=list(data.columns)\n",
    "\n",
    "        # get all columns except vlaue\n",
    "        date_cols=[x for x in data_cols if x !='value']\n",
    "\n",
    "        # add moving average\n",
    "        moving_avg_df=pd.concat([data[date_cols], moving_avg], axis=1)\n",
    "\n",
    "        moving_avg_df.rename(columns={f'{period}-day moving_avg':'value'}, inplace=True)\n",
    "        \n",
    "\n",
    "    return moving_avg_df\n",
    "\n",
    "# Freight rates function\n",
    "def freight_rates(start_y, start_m, start_d, rates, unit, freq, plot, title):\n",
    "    \n",
    "    # Set current date\n",
    "    today=datetime.today()\n",
    "    \n",
    "    # empty data frame to loop through and store\n",
    "    final = pd.DataFrame()\n",
    "    \n",
    "    # Obtain dates object\n",
    "    dates=v.FreightPricingTimeseries().search(\n",
    "        time_min=datetime(start_y, start_m, start_d),\n",
    "        time_max=today,\n",
    "        routes=rates[0],\n",
    "        breakdown_property=unit,\n",
    "        breakdown_frequency=freq).to_df()\n",
    "    \n",
    "    # take just dates column\n",
    "    dates = pd.concat([dates[\"key\"]], axis = 1)\n",
    "    final = dates\n",
    "    final.columns = ['Date']\n",
    "    \n",
    "    # Loop through route codes to obtain each route's freight rates\n",
    "    for i in range(len(rates)):\n",
    "        df=v.FreightPricingTimeseries().search(\n",
    "            time_min=datetime(start_y, start_m, start_d),\n",
    "            time_max=today,\n",
    "            routes=rates[i],\n",
    "            breakdown_property=unit,\n",
    "            breakdown_frequency=freq).to_df()\n",
    "\n",
    "        df2 = df[\"value\"]\n",
    "        final = pd.concat([final, df2], axis = 1)\n",
    "\n",
    "    names = ['Date'] + rates\n",
    "    final.columns = names\n",
    "    final['Date']=pd.to_datetime(final['Date'])\n",
    "    \n",
    "        \n",
    "    # Replace blanks with pandas NA values\n",
    "    final.replace('', pd.NA, inplace=True)\n",
    "    \n",
    "    # Remove NAs\n",
    "    final.dropna(inplace=True)\n",
    "\n",
    "    # If desired, plot rates\n",
    "    if plot:\n",
    "        \n",
    "        # Plot rates\n",
    "        fig = px.line(\n",
    "            final,\n",
    "            x=\"Date\", \n",
    "            y=list(final.columns)[1:],\n",
    "            title=title,\n",
    "            labels={\n",
    "                \"Date\":\"Date\",\n",
    "            },\n",
    "            )\n",
    "        fig.update_layout(xaxis_rangeslider_visible = True)\n",
    "        fig.show()\n",
    "    \n",
    "    # Reformat dates for export to excel\n",
    "    final['Date']=final['Date'].dt.strftime(\"%d-%m-%Y\")\n",
    "\n",
    "    \n",
    "    return final\n",
    "\n",
    "\n",
    "# Vessel avaialbility function\n",
    "def vessel_availability(start_y, start_m, start_d, region, port, prod, prod_excl, vessel_class, vessel_class_excl, heading_to, heading_to_excl, status, laycan_min, laycan_max, ma_period, plot, title):\n",
    "\n",
    "    today=datetime.today()\n",
    "    \n",
    "    # Pull avalability time series data\n",
    "    ts_result = v.VesselAvailabilityTimeseries().search(\n",
    "        filter_time_min=datetime(start_y, start_m, start_d),\n",
    "        filter_time_max=today,\n",
    "        filter_region=region,\n",
    "        filter_port=port,\n",
    "        filter_products=prod,\n",
    "        exclude_products=prod_excl,\n",
    "        filter_vessel_classes=vessel_class,\n",
    "        exclude_vessel_classes=vessel_class_excl,\n",
    "        filter_destination=heading_to,\n",
    "        exclude_destination=heading_to_excl,\n",
    "        filter_days_to_arrival=[{\"min\": laycan_min, \"max\": laycan_max}], # specify laycan window\n",
    "        filter_vessel_scrubbers=\"disabled\",\n",
    "        filter_vessel_status=status,\n",
    "        use_reference_port=True\n",
    "        ).to_df()\n",
    "    \n",
    "    ts_result=pd.concat([ts_result[\"key\"], ts_result[\"count\"]], axis=1)\n",
    "    ts_result.columns=[\"Date\", 'Availability']\n",
    "    \n",
    "    if ma_period != None:\n",
    "        ts_result=moving_average(data=ts_result, period=ma_period, option='multiple')\n",
    "        ts_result.columns=[\"Date\", f'Availability ({ma_period}-day MA)']\n",
    "\n",
    "    \n",
    "    if plot: # plot data if desired\n",
    "\n",
    "        fig = px.line(\n",
    "            ts_result, # data to plot\n",
    "            title=title, # title set as input\n",
    "            x=\"Date\",\n",
    "            y=list(ts_result.columns)[1:],\n",
    "            labels={\n",
    "                \"value\":'No. of vessels' # unit label\n",
    "            },\n",
    "            )\n",
    "        fig.update_layout(xaxis_rangeslider_visible = True)\n",
    "        fig.show()\n",
    "    \n",
    "    ts_result['Date']=ts_result['Date'].dt.strftime('%d-%m-%Y')\n",
    "    \n",
    "    return ts_result\n",
    "\n",
    "def fr_va_combination(start_y, start_m, start_d, region, port, prod, prod_excl, vessel_class, vessel_class_excl, heading_to, heading_to_excl, status, laycan_min, laycan_max, va_ma_period, rates, unit, plot, title):\n",
    "    \n",
    "    \n",
    "    frs_df=freight_rates(start_y=start_y, start_m=start_m, start_d=start_d,  \n",
    "                         rates=rates, unit=unit, freq='day', \n",
    "                         plot=False, title='freight rates')\n",
    "\n",
    "\n",
    "    va_df=vessel_availability(start_y=start_y, start_m=start_m, start_d=start_d, \n",
    "                              region=region, port=port, \n",
    "                              prod=prod, prod_excl=prod_excl, \n",
    "                              vessel_class=vessel_class, vessel_class_excl=vessel_class_excl, \n",
    "                              heading_to=heading_to, heading_to_excl=heading_to_excl, \n",
    "                              status=status, laycan_min=laycan_min, laycan_max=laycan_max, \n",
    "                              ma_period=va_ma_period,\n",
    "                              plot=False, title='availability')\n",
    "    \n",
    "    combined_df=pd.merge(frs_df, va_df, on='Date', how='left')\n",
    "    \n",
    "    combined_df['Date']=pd.to_datetime(combined_df['Date'], format=\"%d-%m-%Y\", errors='coerce')\n",
    "    \n",
    "    # Convert all integer columns to floats\n",
    "    combined_df[list(combined_df.columns)[1]]=combined_df[list(combined_df.columns)[1]].astype(float)\n",
    "    combined_df[list(combined_df.columns)[2]]=combined_df[list(combined_df.columns)[2]].astype(float)\n",
    "    \n",
    "    if unit=='cost':\n",
    "        fr_unit='$/ton'\n",
    "        \n",
    "    elif unit=='tce':\n",
    "        fr_unit='$/day'\n",
    "        \n",
    "    elif unit=='route':\n",
    "        fr_unit='WS'\n",
    "\n",
    "    if plot:\n",
    "        \n",
    "        fig = go.Figure()\n",
    "\n",
    "        # Add first line (LHS y-axis)\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=combined_df['Date'],\n",
    "                y=combined_df[list(combined_df.columns)[1]],\n",
    "                name=list(combined_df.columns)[1],\n",
    "                yaxis='y1'\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Add second trace (RHS y-axis)\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=combined_df['Date'],\n",
    "                y=combined_df[list(combined_df.columns)[2]],\n",
    "                name=list(combined_df.columns)[2],\n",
    "                yaxis='y2'\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Update layout to include secondary y-axis\n",
    "        fig.update_layout(\n",
    "            title=title,\n",
    "            xaxis=dict(\n",
    "                title='Date'\n",
    "            ),\n",
    "            yaxis=dict(\n",
    "                title=fr_unit\n",
    "            ),\n",
    "            yaxis2=dict(\n",
    "                title='No. of vessels',\n",
    "                overlaying='y',\n",
    "                side='right'\n",
    "            ),\n",
    "            xaxis_rangeslider_visible=True\n",
    "        )\n",
    "\n",
    "        fig.show()\n",
    "    \n",
    "#     combined_df['Date']=combined_df['Date'].dt.strftime('%d/%m/%Y')\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "# Function to test causality between availability and a freight rate for multiple laycan and moving average combinations\n",
    "def find_highest_causality(ma_max, ma_step, laycan_min, laycan_max, laycan_step, max_lag, alpha, start_y, start_m, start_d, region, port, prod, prod_excl, vessel_class, vessel_class_excl, heading_to, heading_to_excl, status, rates, unit):\n",
    "\n",
    "    # intialise a data frame to store test results\n",
    "    results_df=pd.DataFrame()\n",
    "\n",
    "    # create list of MA periods to use\n",
    "    mas_to_use=[]\n",
    "    for i in range(0, (ma_max + ma_step), ma_step):\n",
    "\n",
    "        if i==0:\n",
    "            mas_to_use.append(1)\n",
    "\n",
    "        else:\n",
    "            mas_to_use.append(i)\n",
    "\n",
    "    mas_to_use=list(set(mas_to_use))\n",
    "    mas_to_use.sort()\n",
    "    mas_to_use=[x for x in mas_to_use if x <= ma_max]\n",
    "\n",
    "\n",
    "    # create list of laycans to use\n",
    "    laycans_to_use=[]\n",
    "    for i in range(laycan_min, (laycan_max+1), laycan_step):\n",
    "\n",
    "        for j in range((i+1), (laycan_max+1)):\n",
    "\n",
    "            add=(i, j)\n",
    "            laycans_to_use.append(add)\n",
    "\n",
    "\n",
    "    # loop through each laycan and each MA period\n",
    "    for laycan in laycans_to_use:\n",
    "\n",
    "        for ma_p in mas_to_use:\n",
    "\n",
    "            # update me\n",
    "            print(f'Currently loading {ma_p}-day MA data for {laycan[0]} to {laycan[1]} days')\n",
    "\n",
    "            # query availability & freight price date combination\n",
    "            data=fr_va_combination(start_y=start_y, start_m=start_m, start_d=start_d, \n",
    "                      region=region, port=port, \n",
    "                      prod=prod, prod_excl=prod_excl, \n",
    "                      vessel_class=vessel_class, vessel_class_excl=vessel_class_excl, \n",
    "                      heading_to=heading_to, heading_to_excl=heading_to_excl, \n",
    "                      status=status, laycan_min=laycan[0], laycan_max=laycan[1], va_ma_period=ma_p,\n",
    "                      rates=rates, unit=unit, plot=False, \n",
    "                      title=None)\n",
    "\n",
    "            # test data\n",
    "            test_result = grangercausalitytests(data[[list(data.columns)[2], list(data.columns)[1]]], max_lag, verbose=False)\n",
    "\n",
    "            # initialise lists to store combination details and test results\n",
    "            laycan_list=[]\n",
    "            p_vals_list=[]\n",
    "            lags_list=[]\n",
    "            mas_list=[]\n",
    "\n",
    "            for lag in range(1, (max_lag + 1), 1):\n",
    "\n",
    "                laycan_add=f'{laycan[0]} - {laycan[1]} days'\n",
    "                p_val=test_result[lag][0]['ssr_ftest'][1]\n",
    "\n",
    "                laycan_list.append(laycan_add)\n",
    "                p_vals_list.append(p_val)\n",
    "                lags_list.append(lag)\n",
    "                mas_list.append(ma_p)\n",
    "\n",
    "            # convert to data frames\n",
    "            laycan_df=pd.DataFrame(laycan_list, columns=['laycan'])\n",
    "            p_vals_df=pd.DataFrame(p_vals_list, columns=['p-value'])\n",
    "            lags_df=pd.DataFrame(lags_list, columns=['lag'])\n",
    "            mas_df=pd.DataFrame(mas_list, columns=['ma_period'])\n",
    "\n",
    "            # combine results\n",
    "            granger_df=pd.concat([laycan_df, p_vals_df, lags_df, mas_df], axis=1)\n",
    "\n",
    "            # add to master\n",
    "            results_df=pd.concat([results_df, granger_df])\n",
    "            \n",
    "            \n",
    "    # sort by statistical significance and reset indices\n",
    "    results_df.sort_values(by='p-value', ascending=True, inplace=True)\n",
    "    results_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # apply Bonferonni correction\n",
    "    corrected_alpha=alpha/len(results_df)\n",
    "    print(\" \")\n",
    "    print(f'Corrected alpha level based on {len(results_df)} tests: {corrected_alpha}')\n",
    "    results_df.loc[results_df['p-value']<=corrected_alpha, 'decision'] = 'causality'\n",
    "    results_df.loc[results_df['p-value']>corrected_alpha, 'decision'] = 'no causality'\n",
    "\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dd10c3",
   "metadata": {},
   "source": [
    "# Worked example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1869ef5",
   "metadata": {},
   "source": [
    "First, we need to loop through a few combinations of laycan periods and moving averages to find combinations of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd280a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T10:25:24.510162Z",
     "start_time": "2024-09-17T10:24:19.593285Z"
    }
   },
   "outputs": [],
   "source": [
    "c_test=find_highest_causality(ma_max=21, ma_step=7, \n",
    "                              laycan_min=5, laycan_max=25, laycan_step=5, \n",
    "                              max_lag=10, alpha=0.05, \n",
    "                              start_y=2024, start_m=4, start_d=1, \n",
    "                              region=padd3, port=None, \n",
    "                              prod=crude_co, prod_excl=None, \n",
    "                              vessel_class='oil_aframax_lr2', vessel_class_excl=None, \n",
    "                              heading_to=None, heading_to_excl=None, status=None, \n",
    "                              rates=['TD25'], unit='cost')\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3923d7",
   "metadata": {},
   "source": [
    "Now let's view the results sorted by p-value from most to least significant. \n",
    "\n",
    "**Note:** Some results may not be *technically* statistically significant, however, can still exhibit strong predictability when viewed alongside freight rates. The choice of candidates depends on technical suitability as well as suitability in the context of the market being analysed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b961bc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T10:25:24.514908Z",
     "start_time": "2024-09-17T10:24:23.476Z"
    }
   },
   "outputs": [],
   "source": [
    "c_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7cd25d",
   "metadata": {},
   "source": [
    "Filter for a specific lag if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f589a55b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T10:25:24.516060Z",
     "start_time": "2024-09-17T10:24:25.388Z"
    }
   },
   "outputs": [],
   "source": [
    "c_test[(c_test['lag']>=3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a682e1",
   "metadata": {},
   "source": [
    "Now we can query candidate combinations to see how the time series interact with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1e5dc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T10:04:15.625590Z",
     "start_time": "2024-08-12T10:04:09.969238Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tryouts=fr_va_combination(start_y=2024, start_m=4, start_d=1, \n",
    "                          region=padd3, port=None, \n",
    "                          prod=crude_co, prod_excl=None, \n",
    "                          vessel_class='oil_aframax_lr2', vessel_class_excl=None, \n",
    "                          heading_to=None, heading_to_excl=None, \n",
    "                          status=None, laycan_min=4, laycan_max=8, va_ma_period=14,\n",
    "                          rates=['TD25'], unit='cost', plot=True, \n",
    "                          title='TD25 freight rate vs Aframax availability in the GoM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e845a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
